params = {
    'embedding_dim': 1024,
    'transformer_dim': 1024,
    'transformer_dropout': 0.2,
    'lstm_units_1': 512,
    'dropout_1': 0.3,
    'lstm_units_2': 256,
    'dense_units': 1463,
    'dropout_2': 0.3,
    'optimizer': 'relu',
    'loss': 'categorical_crossentropy',
    'epochs': 1000,
    'batch_size': 64,
    'l1': 0.01,
    'l2': 0.01,
    'output_activation': 'softmax',
    'lr': 0.003,
}